{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NUbZQyrJ14yaKoZpy3RvArmoi2i-emo0",
      "authorship_tag": "ABX9TyOT21+i3RgHFfTK1YhJWYPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshiAbolghasemi/AI-UT/blob/main/clustering/image_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we want using clustering algorithms, analysing flowers pictures an d then based on our data put them into different clusters"
      ],
      "metadata": {
        "id": "vK3wa1HKFC4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports And Settings"
      ],
      "metadata": {
        "id": "9NqeL8Mbm6cH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "UhlbxgT_YqZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Model\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "f9cPVDYtm8nR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "msBu3DXHYwvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH=os.path.join(os.getcwd(), 'drive/MyDrive/AI-UT/clustering/data')\n",
        "FLOWER_IMAGES_PATH=os.path.join(DATASET_PATH, 'flower_images/')\n",
        "\n",
        "IMG_HEIGHT=224\n",
        "IMG_WIDTH=224"
      ],
      "metadata": {
        "id": "gxtrM9EFa6fp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "JbYK-jO-0Vrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKNa0_Om0YrP",
        "outputId": "a82f7263-dfd4-4dfc-fe19-fd97a4b84220"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing and Feature Extraction\n",
        "In this section, we are going to extract information from images using VGG16."
      ],
      "metadata": {
        "id": "ieaFk7NWhddj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why do we need feature extraction? why dont we only read raw pixel? explain it.\n",
        "> Instead of using the raw pixels directly, features represent more abstract and meaningful characteristics, such as edges, textures, or shapes.<br>\n",
        "> Advantages of feature extraction include:<br>\n",
        "> - **Dimensionality Reduction:** Extracted features often have lower dimensionality than raw pixel data, reducing the complexity of the data and computation.\n",
        "> -**Increased Robustness:** Features focus on important aspects, making models more robust to variations like changes in lighting, rotation, or scale.\n",
        "> - **Improved Generalization:** Features highlight relevant information, helping models generalize better to new, unseen data by emphasizing key patterns.\n",
        "> - **Enhanced Interpretability:** Features can provide insights into the image content, aiding in the interpretability of the model's decisions.\n",
        "> - **Computational Efficiency:** Working with extracted features is computationally more efficient than processing raw pixel values, enabling faster training and inference. <br>\n",
        "> - Overall, feature extraction enhances the performance and interpretability of image processing models by transforming raw pixel data into a more meaningful and manageable representation.\n",
        "\n",
        "2. Explain three ways of feature extraction Theqniques from images.\n",
        ">- **Convolutional Neural Networks(CNN)**: CNNs are generally the preferred choice for feature extraction from images because CNNs are specifically designed for processing color images and perform more complex tasks such as image classification, object detection, or segmentation where it can extract complex and descriptive features with any variations such as lighting conditions, scale, and other factors in the image. It is useful in situations where you want to have high accuracy after processing your images, thus making it the most efficient way.<br>\n",
        ">- **Mean pixel values of channels**: It is a very basic image feature extraction technique where we calculate the mean intensity of each color channel (red, green, and blue) in an image. This approach can be useful in situations where the goal is to perform a simple image processing operation or to obtain a basic representation of the image such as thumbnail creation, image compression and resizing. However, mean pixel value of channels is generally not a suitable technique for more complex tasks such as image classification, object detection, or segmentation. This is because mean pixel value of channels does not take into account the spatial relationship between the pixels in the image, and it does not consider the relationship between different channels.<br>\n",
        ">- **Local Binary Patterns (LBP)**: Local Binary Patterns (LBP) is a widely used feature extraction method for analyzing texture information in images. LBP captures the local structure of an image by comparing the gray values of a pixel to its surrounding neighbors and encoding the result into a binary pattern. LBP features are often used where there is limited data and in machine learning algorithms for various computer vision tasks such as face recognition, texture analysis, and object recognition. LBP is computationally efficient and can operate in real-time applications, such as surveillance and tracking systems, where the processing speed is crucial.\n",
        "\n",
        "3. Which preprocessing should be applied to image data to prepare it for input into a model?\n",
        "> There are several techniques used in image preprocessing:\n",
        "> - Resizing: Resizing images to a uniform size is important for machine learning algorithms to function properly.\n",
        "> - Grayscaling: Converting color images to grayscale can simplify your image data and reduce computational needs for some algorithms.\n",
        "> - Noise reduction: Smoothing, blurring, and filtering techniques can be applied to remove unwanted noise from images.\n",
        "> - Normalization: Normalization adjusts the intensity values of pixels to a desired range, often between 0 to 1. This can improve the performance of machine learning models.\n",
        "> - Binarization: Binarization converts grayscale images to black and white by thresholding.\n",
        "> - Contrast enhancement: The contrast of images can be adjusted using histogram equalization."
      ],
      "metadata": {
        "id": "4MWWX2cV5T22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset\n",
        "First Let's read our image dataset"
      ],
      "metadata": {
        "id": "DTQKoVi8aqhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Flower:\n",
        "  image: np.ndarray\n",
        "  label: str\n",
        "  features: np.ndarray"
      ],
      "metadata": {
        "id": "R_0syGVC57hu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images() -> List[Flower]:\n",
        "  flowers = []\n",
        "  labels = pd.read_csv(os.path.join(DATASET_PATH, 'flower_labels.csv'))\n",
        "  for flower_image in os.listdir(FLOWER_IMAGES_PATH):\n",
        "    try:\n",
        "      image = cv2.imread(os.path.join(FLOWER_IMAGES_PATH, flower_image))\n",
        "      if image is None:\n",
        "        print(f\"failed to read {flower_image}.\")\n",
        "        continue\n",
        "      label = labels.loc[labels.file == flower_image, 'label'].iloc[0]\n",
        "      flowers.append(Flower(image=cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT)),\n",
        "                            label=label,\n",
        "                            features=None))\n",
        "    except Exception as e:\n",
        "      print(f\"{str(e)}\")\n",
        "\n",
        "  return flowers"
      ],
      "metadata": {
        "id": "UCsiiouiauxr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flowers = load_images()"
      ],
      "metadata": {
        "id": "6h8Sp09q4ZnR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n"
      ],
      "metadata": {
        "id": "6_VIFI7u3d8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's create our VGG16 model"
      ],
      "metadata": {
        "id": "kDcYbW2F_x8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = VGG16(weights='imagenet',\n",
        "              include_top=False,\n",
        "              input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "vgg16.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30pHqPSAIsDv",
        "outputId": "5b90c04f-e4fb-4005-b2bd-63f300d3cd13"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, using VGG16, we are going to extract features from our images."
      ],
      "metadata": {
        "id": "n1Ut-YP5IrbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(flowers: List[Flower], model: VGG16=vgg16) -> None:\n",
        "  feat_extractor = Model(inputs=model.input, outputs=model.output)\n",
        "  for flower in flowers:\n",
        "    img = flower.image\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    flower.features = model.predict(img)"
      ],
      "metadata": {
        "id": "OVv3liWb_14C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(flowers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHGSdX8bYpMQ",
        "outputId": "e55c3099-f2a5-4bae-d6a6-2cbdb8d298d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 707ms/step\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "1/1 [==============================] - 1s 539ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 594ms/step\n",
            "1/1 [==============================] - 1s 907ms/step\n",
            "1/1 [==============================] - 1s 899ms/step\n",
            "1/1 [==============================] - 1s 939ms/step\n",
            "1/1 [==============================] - 1s 928ms/step\n",
            "1/1 [==============================] - 1s 682ms/step\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 559ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 527ms/step\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "1/1 [==============================] - 1s 533ms/step\n",
            "1/1 [==============================] - 1s 539ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 563ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "1/1 [==============================] - 1s 932ms/step\n",
            "1/1 [==============================] - 1s 910ms/step\n",
            "1/1 [==============================] - 1s 985ms/step\n",
            "1/1 [==============================] - 1s 898ms/step\n",
            "1/1 [==============================] - 1s 725ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 1s 529ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 555ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 528ms/step\n",
            "1/1 [==============================] - 1s 543ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 1s 532ms/step\n",
            "1/1 [==============================] - 1s 836ms/step\n",
            "1/1 [==============================] - 1s 933ms/step\n",
            "1/1 [==============================] - 1s 962ms/step\n",
            "1/1 [==============================] - 1s 904ms/step\n",
            "1/1 [==============================] - 1s 898ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "1/1 [==============================] - 1s 535ms/step\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "1/1 [==============================] - 1s 535ms/step\n",
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 817ms/step\n",
            "1/1 [==============================] - 1s 923ms/step\n",
            "1/1 [==============================] - 1s 919ms/step\n",
            "1/1 [==============================] - 1s 932ms/step\n",
            "1/1 [==============================] - 1s 886ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 1s 541ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 558ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 543ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 550ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 533ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 541ms/step\n",
            "1/1 [==============================] - 1s 756ms/step\n",
            "1/1 [==============================] - 1s 962ms/step\n",
            "1/1 [==============================] - 1s 912ms/step\n",
            "1/1 [==============================] - 1s 929ms/step\n",
            "1/1 [==============================] - 1s 899ms/step\n",
            "1/1 [==============================] - 1s 999ms/step\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 554ms/step\n",
            "1/1 [==============================] - 1s 554ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 552ms/step\n",
            "1/1 [==============================] - 1s 539ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 847ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 987ms/step\n",
            "1/1 [==============================] - 1s 762ms/step\n",
            "1/1 [==============================] - 1s 949ms/step\n",
            "1/1 [==============================] - 1s 925ms/step\n",
            "1/1 [==============================] - 1s 954ms/step\n",
            "1/1 [==============================] - 1s 923ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 554ms/step\n",
            "1/1 [==============================] - 1s 543ms/step\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 554ms/step\n",
            "1/1 [==============================] - 1s 533ms/step\n",
            "1/1 [==============================] - 1s 550ms/step\n",
            "1/1 [==============================] - 1s 555ms/step\n",
            "1/1 [==============================] - 1s 543ms/step\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "1/1 [==============================] - 1s 918ms/step\n",
            "1/1 [==============================] - 1s 945ms/step\n",
            "1/1 [==============================] - 1s 989ms/step\n",
            "1/1 [==============================] - 1s 937ms/step\n",
            "1/1 [==============================] - 1s 727ms/step\n",
            "1/1 [==============================] - 1s 550ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 526ms/step\n",
            "1/1 [==============================] - 1s 555ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "1/1 [==============================] - 1s 539ms/step\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "1/1 [==============================] - 1s 532ms/step\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "1/1 [==============================] - 1s 918ms/step\n",
            "1/1 [==============================] - 1s 920ms/step\n",
            "1/1 [==============================] - 1s 970ms/step\n",
            "1/1 [==============================] - 1s 892ms/step\n",
            "1/1 [==============================] - 1s 727ms/step\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "1/1 [==============================] - 1s 532ms/step\n",
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 1s 529ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 550ms/step\n",
            "1/1 [==============================] - 1s 528ms/step\n",
            "1/1 [==============================] - 1s 552ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 854ms/step\n",
            "1/1 [==============================] - 1s 952ms/step\n",
            "1/1 [==============================] - 1s 914ms/step\n",
            "1/1 [==============================] - 1s 921ms/step\n",
            "1/1 [==============================] - 1s 804ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 532ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 555ms/step\n",
            "1/1 [==============================] - 1s 537ms/step\n",
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 558ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 1s 725ms/step\n",
            "1/1 [==============================] - 1s 970ms/step\n",
            "1/1 [==============================] - 1s 892ms/step\n",
            "1/1 [==============================] - 1s 947ms/step\n",
            "1/1 [==============================] - 1s 888ms/step\n",
            "1/1 [==============================] - 1s 555ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n"
          ]
        }
      ]
    }
  ]
}