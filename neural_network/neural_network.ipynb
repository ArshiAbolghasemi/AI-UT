{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTJMjZ2FeoZlV4vbX/Ze/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshiAbolghasemi/AI-UT/blob/main/neural_network/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we will utilize a text dataset to demonstrate advanced natural language processing techniques. Our approach will involve initial preprocessing of the text, followed by the application of Word2Vec and neural networks to effectively analyze and interpret the data. Through these methods, we aim to uncover meaningful patterns and insights within the text."
      ],
      "metadata": {
        "id": "LNv007UOa5l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Settings"
      ],
      "metadata": {
        "id": "pg1vvEfemG-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "8Q3waVQnpzK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "d_XniedQ5YAB",
        "outputId": "23a199dd-1775-419d-e3ce-6a5e71e0e73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/431.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/431.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.1)\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim.downloader as api\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from emoji import demojize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from random import randint, random\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "klKvEUJVp0XE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "aWlwiXlZqJA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_MOUNTED_PATH=os.path.join(os.getcwd(), 'drive/')\n",
        "TWITTER_SUICIDAL_DATASET_PATH=os.path.join(DRIVE_MOUNTED_PATH, 'MyDrive/AI-UT/neural_network/twitter-suicidal-data.csv')"
      ],
      "metadata": {
        "id": "u8ZsSUF5qKhB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device Configuration"
      ],
      "metadata": {
        "id": "deix3T4B9Zru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "EiA2OWXb9cA8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting to Google Drive"
      ],
      "metadata": {
        "id": "5SF7nRp3p0p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(DRIVE_MOUNTED_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6EZ_ji1qEK1",
        "outputId": "4e874309-a9e6-4a75-d11d-219e1ae490c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "MxDjNEfX8JH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Dataset"
      ],
      "metadata": {
        "id": "UqnBWzqn8MW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data = pd.read_csv(TWITTER_SUICIDAL_DATASET_PATH)"
      ],
      "metadata": {
        "id": "BW2zcmGf8R67"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bRv_q_Fp8xzO",
        "outputId": "a0201bca-f216-49bf-a151-4a8acfe10cb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tweet  intention\n",
              "0     my life is meaningless i just want to end my l...          1\n",
              "1     muttering i wanna die to myself daily for a fe...          1\n",
              "2     work slave i really feel like my only purpose ...          1\n",
              "3     i did something on the 2 of october i overdose...          1\n",
              "4     i feel like no one cares i just want to die ma...          1\n",
              "...                                                 ...        ...\n",
              "9114  have you ever laid on your bed at night and cr...          1\n",
              "9115  the fault the blame the pain s still there i m...          1\n",
              "9116  stop asking me to trust you when i m still cou...          1\n",
              "9117  i never know how to handle sadness crying make...          1\n",
              "9118  when cancer takes a life we blame cancer depre...          1\n",
              "\n",
              "[9119 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3efb81b-d9cd-4247-83d0-ea57dfd3ccd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>intention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did something on the 2 of october i overdose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9114</th>\n",
              "      <td>have you ever laid on your bed at night and cr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>the fault the blame the pain s still there i m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9116</th>\n",
              "      <td>stop asking me to trust you when i m still cou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9117</th>\n",
              "      <td>i never know how to handle sadness crying make...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9118</th>\n",
              "      <td>when cancer takes a life we blame cancer depre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9119 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3efb81b-d9cd-4247-83d0-ea57dfd3ccd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3efb81b-d9cd-4247-83d0-ea57dfd3ccd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3efb81b-d9cd-4247-83d0-ea57dfd3ccd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa56fc29-9643-410c-bc37-9f5d2bfc6a22\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa56fc29-9643-410c-bc37-9f5d2bfc6a22')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa56fc29-9643-410c-bc37-9f5d2bfc6a22 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "twitter_suicidal_data",
              "summary": "{\n  \"name\": \"twitter_suicidal_data\",\n  \"rows\": 9119,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8785,\n        \"samples\": [\n          \"i am so frustrated i hanged myself 6 and half weeks ago i barely survived i have a scar on my neck from the 12 inch manilla that cut into my neck yet all i can think of right now is blowing my head off i am on 20mg lexapro 10mg zyprexa and 100mg lamotrigine i spent all of yesterday cutting into my chest because the pain makes not see the hallucinations i get every hour of every day i just want to live a normal life\",\n          \"cold shower ftw too bad clothes had to be put back on it s too hot \",\n          \"rip jack kemp a great american patriot i always wanted to meet and now never will \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intention\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data_cleaned = twitter_suicidal_data.copy()"
      ],
      "metadata": {
        "id": "FY-D-eBV9RWX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to lowercase"
      ],
      "metadata": {
        "id": "dwgkvGU_9MEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting all text to lowercase ensures uniformity. It helps in matching words correctly regardless of their case, reducing redundancy (e.g., \"Python\" and \"python\" are considered the same word).\n",
        "<br>\n",
        "Pros:\n",
        "- **Normalization**: Converting text to lowercase helps normalize the text by ensuring consistency. It treats words with different cases (e.g., \"Hello\", \"hello\", \"HELLO\") as the same, which can simplify text processing and analysis.\n",
        "\n",
        "- **Reduced Vocabulary Size**: Lowercasing reduces the number of distinct tokens in the text, which can improve the efficiency of downstream tasks such as tokenization, indexing, and modeling. This is particularly beneficial for tasks with limited computational resources.\n",
        "\n",
        "- **Improved Matching**: Lowercasing facilitates case-insensitive matching. This is useful in tasks such as search, comparison, and retrieval, where case sensitivity might not be desired or necessary.\n",
        "\n",
        "- **Standardization**: Lowercasing helps standardize text data, making it consistent across different sources, systems, and languages. It ensures that text processing pipelines produce consistent results regardless of the original casing.\n",
        "\n",
        "Cons:\n",
        "- **Loss of Information**: Lowercasing can lead to the loss of information, especially in cases where the distinction between uppercase and lowercase letters is semantically meaningful. For example, proper nouns, acronyms, and emphasis can be lost when converted to lowercase.\n",
        "\n",
        "- **Misinterpretation of Entities**: Lowercasing can potentially alter the interpretation of named entities (e.g., \"USA\" to \"usa\"), leading to ambiguity or misinterpretation in text analysis tasks, such as named entity recognition or entity disambiguation.\n",
        "\n",
        "- **Loss of Emphasis**: Lowercasing removes emphasis conveyed by uppercase letters, which might be important for conveying tone, emphasis, or significance in the text. This can affect tasks such as sentiment analysis or text summarization."
      ],
      "metadata": {
        "id": "qg96Ob8e9j8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Punctuation"
      ],
      "metadata": {
        "id": "VRLT9_LQ9pMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Punctuation marks are generally not useful in most text analysis tasks (e.g., sentiment analysis) and can be removed to focus on the words themselves. This step simplifies tokenization and text processing."
      ],
      "metadata": {
        "id": "KXjN_mJK9r_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Numbers"
      ],
      "metadata": {
        "id": "uyE2yzW_9u-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numbers in text data, especially from social media, can be noisy and might not contribute meaningfully to the analysis. For example, random numbers, dates, and phone numbers often do not hold significant value in text sentiment analysis or other NLP tasks.\n",
        "<br>\n",
        "Pros:\n",
        "- **Improved Text Clarity**: Removing numbers can make the text clearer and more readable, especially in tasks like sentiment analysis, topic modeling, or text summarization, where numbers might not contribute to the overall meaning.\n",
        "\n",
        "- **Reduced Vocabulary Size**: By eliminating numbers, you reduce the size of the vocabulary, which can simplify text processing tasks such as tokenization, indexing, and modeling. This can lead to more efficient algorithms and reduced computational overhead.\n",
        "\n",
        "- **Focused Analysis**: In some cases, numbers are noise that distracts from the main content of the text. By removing them, you can focus your analysis on the relevant textual information, leading to more accurate results.\n",
        "\n",
        "Cons:\n",
        "- **Loss of Information**: Removing numbers may result in the loss of valuable information, especially in contexts where numerical data is significant, such as financial reports, scientific documents, or technical manuals. The presence of numbers can convey quantitative information, dates, measurements, or other important details.\n",
        "\n",
        "- **Altered Meaning**: In certain text analysis tasks, such as sentiment analysis or opinion mining, numbers may carry emotional or contextual significance. Removing them could potentially alter the meaning or sentiment of the text, leading to misinterpretation.\n",
        "\n",
        "- **Impact on Tasks**: Removing numbers may not be suitable for all tasks or datasets. In some cases, such as text classification based on numerical patterns or sentiment analysis of numerical reviews, preserving numbers might be essential for accurate analysis."
      ],
      "metadata": {
        "id": "JqRPl3ayM-jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove URLs"
      ],
      "metadata": {
        "id": "-3yl1ORv99M3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "URLs are often not useful for text analysis and can introduce noise. They usually don't contribute to the sentiment or meaning of the tweet and can be safely removed to focus on the actual content."
      ],
      "metadata": {
        "id": "b5V61R-u-Cro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Mentions"
      ],
      "metadata": {
        "id": "lfOjqevO-Mo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mentions (e.g., @elonmusk) are specific to Twitter and do not usually contribute to the semantic content of the text. Removing them helps in focusing on the message rather than the addressed users."
      ],
      "metadata": {
        "id": "7dfOohQa-N3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Emojis"
      ],
      "metadata": {
        "id": "XRDHJYu6-aPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emojis can convey sentiment and meaning, but they might complicate text processing. If the analysis does not benefit from emojis, removing them can simplify the text. However, if you are interested in the sentiment or emotional content, you might want to keep them or replace them with corresponding text descriptions."
      ],
      "metadata": {
        "id": "Cg3Kxr6v-bbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Space Uniformity"
      ],
      "metadata": {
        "id": "AzeCMmjdHwtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ensuring uniformity of spaces is an important step in text preprocessing. It involves removing extra spaces, leading and trailing spaces, and ensuring that words are properly separated by a single space. This helps in maintaining consistency and avoiding potential issues in tokenization or further analysis."
      ],
      "metadata": {
        "id": "G9qg8ex4HxcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "oC3PUSvdHz6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization splits the text into individual words (tokens). This is a crucial step for many text processing tasks like filtering out stopwords, analyzing word frequencies, and further text analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "YYhbuoNnIRTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Stopwords"
      ],
      "metadata": {
        "id": "UrDceEmpIUYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords (e.g., \"and\", \"is\", \"in\") are common words that usually do not carry significant meaning and can be removed to focus on the more meaningful words. This reduces the dimensionality of the data and improves analysis efficiency."
      ],
      "metadata": {
        "id": "KWw2sG_-IU90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Hashtags"
      ],
      "metadata": {
        "id": "1gY6hB-DN6M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preserving hashtags in suicidal tweets can provide valuable contextual information and improve model accuracy in certain cases, but it also carries risks of introducing noise, overfitting, and ethical concerns. The impact on model accuracy depends on various factors, including the quality of the data, the task at hand, and the design of the model. Therefore, it's crucial to carefully evaluate the trade-offs and implications of preserving hashtags in suicidal tweets and to adopt appropriate strategies for mitigating potential risks while maximizing the benefits of contextual information."
      ],
      "metadata": {
        "id": "FV7oZ7y4N7-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "e6vA0BOvJLwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "U2gvTC9uJI3Z",
        "outputId": "43e1c3e6-e3fa-4a88-80a5-8594d215b061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweet(tweet):\n",
        "  tweet = tweet.lower()\n",
        "  tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "  tweet = re.sub(r'\\d+', '', tweet)\n",
        "  tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
        "  tweet = re.sub(r'@\\w+', '', tweet)\n",
        "  tweet = demojize(tweet)\n",
        "  tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "  return tweet"
      ],
      "metadata": {
        "id": "y0LsIMRKIbQF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_cleaned_tweet(cleaned_tweet):\n",
        "  tokens = word_tokenize(cleaned_tweet)\n",
        "  tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "pn7UTn8uP5FQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data_cleaned['cleaned_tweet'] = twitter_suicidal_data_cleaned['tweet'].apply(preprocess_tweet)"
      ],
      "metadata": {
        "id": "2bmdS866OCJO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tweet = twitter_suicidal_data_cleaned.sample(n=5)"
      ],
      "metadata": {
        "id": "v17CPBqYQtv3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tweet['tweet'].head()"
      ],
      "metadata": {
        "id": "FgXbZCDSPQpi",
        "outputId": "35386af7-16de-4af1-beec-1e857a274e16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5871     the word lunch is making me hungry haha i m g...\n",
              "4167    why is it that i love all the things i shouldn...\n",
              "5829     right i tried quotautomat ipquot thing have t...\n",
              "7209    i just need to leave her alone before i scare ...\n",
              "2813    i want to die tonight i wish i had done it yea...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tweet['cleaned_tweet'].head()"
      ],
      "metadata": {
        "id": "D3bb25HEQVyB",
        "outputId": "55272e60-5a57-482a-a892-9a8d58e511d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5871    the word lunch is making me hungry haha i m go...\n",
              "4167    why is it that i love all the things i shouldn...\n",
              "5829    right i tried quotautomat ipquot thing have tr...\n",
              "7209    i just need to leave her alone before i scare ...\n",
              "2813    i want to die tonight i wish i had done it yea...\n",
              "Name: cleaned_tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data_cleaned['tokens'] = twitter_suicidal_data_cleaned['cleaned_tweet'].apply(tokenize_cleaned_tweet)"
      ],
      "metadata": {
        "id": "yEyT0xrjQzno"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Describe Result"
      ],
      "metadata": {
        "id": "I9fd9NADRavQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data_cleaned.head()"
      ],
      "metadata": {
        "id": "gdirAwuFRpjj",
        "outputId": "42c48efb-c8d0-4e65-fbed-def06f9a7eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  intention  \\\n",
              "0  my life is meaningless i just want to end my l...          1   \n",
              "1  muttering i wanna die to myself daily for a fe...          1   \n",
              "2  work slave i really feel like my only purpose ...          1   \n",
              "3  i did something on the 2 of october i overdose...          1   \n",
              "4  i feel like no one cares i just want to die ma...          1   \n",
              "\n",
              "                                       cleaned_tweet  \\\n",
              "0  my life is meaningless i just want to end my l...   \n",
              "1  muttering i wanna die to myself daily for a fe...   \n",
              "2  work slave i really feel like my only purpose ...   \n",
              "3  i did something on the of october i overdosed ...   \n",
              "4  i feel like no one cares i just want to die ma...   \n",
              "\n",
              "                                              tokens  \n",
              "0  [life, meaningless, want, end, life, badly, li...  \n",
              "1  [muttering, wan, na, die, daily, months, feel,...  \n",
              "2  [work, slave, really, feel, like, purpose, lif...  \n",
              "3  [something, october, overdosed, felt, alone, h...  \n",
              "4  [feel, like, one, cares, want, die, maybe, fee...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbc56892-0059-4e93-b2c6-ed9b2199b71d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>intention</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>1</td>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>[life, meaningless, want, end, life, badly, li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>1</td>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>[muttering, wan, na, die, daily, months, feel,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>1</td>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>[work, slave, really, feel, like, purpose, lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did something on the 2 of october i overdose...</td>\n",
              "      <td>1</td>\n",
              "      <td>i did something on the of october i overdosed ...</td>\n",
              "      <td>[something, october, overdosed, felt, alone, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>1</td>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>[feel, like, one, cares, want, die, maybe, fee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc56892-0059-4e93-b2c6-ed9b2199b71d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbc56892-0059-4e93-b2c6-ed9b2199b71d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbc56892-0059-4e93-b2c6-ed9b2199b71d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33bbc372-c1be-40ff-b08f-a28e029aea03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33bbc372-c1be-40ff-b08f-a28e029aea03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33bbc372-c1be-40ff-b08f-a28e029aea03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "twitter_suicidal_data_cleaned",
              "summary": "{\n  \"name\": \"twitter_suicidal_data_cleaned\",\n  \"rows\": 9119,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8785,\n        \"samples\": [\n          \"i am so frustrated i hanged myself 6 and half weeks ago i barely survived i have a scar on my neck from the 12 inch manilla that cut into my neck yet all i can think of right now is blowing my head off i am on 20mg lexapro 10mg zyprexa and 100mg lamotrigine i spent all of yesterday cutting into my chest because the pain makes not see the hallucinations i get every hour of every day i just want to live a normal life\",\n          \"cold shower ftw too bad clothes had to be put back on it s too hot \",\n          \"rip jack kemp a great american patriot i always wanted to meet and now never will \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intention\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8757,\n        \"samples\": [\n          \"im tiered why do i always work saturday i need a coffee urgent\",\n          \"i feel bad for my cat i didn t feed him this morning before i left\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_suicidal_data_cleaned['token_count'] = twitter_suicidal_data_cleaned['tokens'].apply(len)"
      ],
      "metadata": {
        "id": "Rt-VEVVaRs8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = twitter_suicidal_data_cleaned.groupby('intention')['token_count'].agg(['mean', 'max', 'min'])\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3BlqAonNRlyI",
        "outputId": "26f8114d-1099-4ab8-d7c0-616eec775475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                mean   max  min\n",
            "intention                      \n",
            "0           8.976567    38    0\n",
            "1          73.848424  2147    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=twitter_suicidal_data_cleaned, x='intention', y='token_count', showmeans=True, meanline=True)\n",
        "sns.stripplot(data=twitter_suicidal_data_cleaned, x='intention', y='token_count', jitter=True, color='black', alpha=0.5)\n",
        "plt.title('Distribution of Token Counts for Suicidal and Non-Suicidal Tweets')\n",
        "plt.xlabel('Intention')\n",
        "plt.ylabel('Token Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SpwAM6WfRhMw",
        "outputId": "57c241ce-1efc-46a0-ba99-b3e0b4947dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Vectors"
      ],
      "metadata": {
        "id": "JsHN6Fh5vuXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding"
      ],
      "metadata": {
        "id": "Hs9LnxsFvyNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embeddings are basically representations where contexts and similarities are captured by encoding in a vector space- similar words would have similar representations"
      ],
      "metadata": {
        "id": "o08EghG4wigj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "O8udo32uwkeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "W87jId4f7AT2",
        "outputId": "30fa66bc-89c4-41a2-eb55-ded9798275e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "Deucy80C_bWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding involves adding extra tokens or values to sequences to make them all have the same length. This is often necessary because many machine learning models expect inputs of fixed dimensions. When working with sequences, such as sentences in natural language processing or time series data, it's common to have sequences of different lengths. Padding helps ensure that all sequences are of equal length.\n",
        "\n",
        "- **Zero-Padding**: is a specific type of padding where the extra values added to the sequences are zeros. Zero-padding is widely used because it has minimal impact on the data's original meaning, especially in scenarios like text processing where zero indices don't represent any actual words."
      ],
      "metadata": {
        "id": "BW2jQevB_vBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Out of Vocabulary Words(OOV Words)"
      ],
      "metadata": {
        "id": "vec4hmTTC2mr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Zero-Padding**\n",
        "\n",
        " **Pros**:\n",
        "\n",
        "  *   Simple and easy to implement.\n",
        "  *   Preserves the structure of the input data.\n",
        "  *   Zero vectors don't introduce additional parameters to the model.\n",
        "\n",
        " **Cons**:\n",
        "  *   Loss of information: Zero vectors do not convey any semantic meaning, potentially leading to loss of valuable information.\n",
        "  *  Ineffective for unseen words: Similarity calculations involving OOV words will be inaccurate, as all OOV words are treated the same.\n",
        "\n",
        "\n",
        "2.   **Random Vectors**\n",
        "\n",
        "  **Pros**:\n",
        "  \n",
        "    * Preserves input dimensionality.\n",
        "    * Provides some representation for OOV words.\n",
        "    * Can be useful when dealing with small datasets or rare words.\n",
        "\n",
        "  **Cons**:\n",
        "    * Lack of semantic meaning: Random vectors do not capture any meaningful information about the words.\n",
        "    * Not deterministic: The representations for OOV words will vary randomly during each training session, making it challenging to learn meaningful patterns.\n",
        "\n",
        "3.  **Subword Embeddings**\n",
        "\n",
        "  **Pros**\n",
        "\n",
        "    * Handles OOV words by decomposing words into subword units (n-grams), allowing for the creation of embeddings for unseen words based on their subword components.\n",
        "    * Effective for handling morphologically rich languages and rare words.\n",
        "    * Captures more fine-grained information compared to word-level embeddings.\n",
        "\n",
        "  **Cons**\n",
        "\n",
        "    * Increased computational complexity: Training and inference with subword embeddings can be computationally more expensive than traditional word embeddings.\n",
        "    * Larger memory footprint: Subword embeddings typically require more memory to store due to the increased vocabulary size.\n",
        "\n",
        "4. **Character-Level Embeddings**\n",
        "\n",
        "  **Pros**:\n",
        "\n",
        "    * Generates embeddings directly from characters, allowing the model to learn representations for unseen words based on their character compositions.\n",
        "    * Effective for handling misspellings, morphological variations, and rare words.\n",
        "    * Encodes subword information, making it robust to unseen words and languages with complex morphology.\n",
        "    \n",
        "  **Cons**:\n",
        "\n",
        "    * Increased model complexity: Character-level embeddings require more parameters and computational resources compared to word-level embeddings.\n",
        "    * Longer training time: Training character-level embeddings can be slower due to the increased dimensionality of the input data.\n",
        "5. **OOV Word Handling Strategies during Training**\n",
        "  \n",
        "  **Pros**:\n",
        "\n",
        "    * Adaptive approach: Dynamically updates word representations during training based on the context and similarity to known words.\n",
        "    * Provides a more nuanced representation for OOV words compared to fixed methods like zero or random vectors.\n",
        "    * Can be combined with other techniques for improved performance.\n",
        "\n",
        "  **Cons**:\n",
        "\n",
        "    * Complexity: Requires specialized algorithms and additional training procedures to handle OOV words effectively.\n",
        "    * Risk of overfitting: Adapting representations for OOV words based on limited context may lead to overfitting, especially in data-poor scenarios.\n"
      ],
      "metadata": {
        "id": "20x50UyfDH1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "tvZh-9uz_5cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tweet_features_vector(tweet_tokens, tweet_token_length=64,\n",
        "                             token_feature_vector_len=w2v.vector_size,\n",
        "                             model=w2v):\n",
        "  tweet_vectors = np.zeros((tweet_token_length, token_feature_vector_len))\n",
        "  for idx, token in enumerate(tweet_tokens[:tweet_token_length]):\n",
        "    if not token in model.key_to_index:\n",
        "      continue\n",
        "\n",
        "    tweet_vectors[idx] = model[token]\n",
        "\n",
        "  return tweet_vectors"
      ],
      "metadata": {
        "id": "e58gQtIDA8yn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features_vector = twitter_suicidal_data_cleaned['tokens'].apply(get_tweet_features_vector)"
      ],
      "metadata": {
        "id": "NU5fiJpdCQSM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features_vector"
      ],
      "metadata": {
        "id": "G6ADV6b-CrB9",
        "outputId": "e607ef9d-8a98-45a7-f655-bf62f4299a56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [[-0.06787109375, 0.09521484375, 0.03564453125...\n",
              "1       [[0.234375, -0.02294921875, 0.1826171875, 0.12...\n",
              "2       [[-0.07568359375, 0.03369140625, -0.0649414062...\n",
              "3       [[0.1123046875, 0.018310546875, 0.0771484375, ...\n",
              "4       [[-0.0556640625, 0.01373291015625, -0.14160156...\n",
              "                              ...                        \n",
              "9114    [[-0.2255859375, -0.032470703125, 0.0402832031...\n",
              "9115    [[-0.02490234375, -0.37890625, 0.330078125, 0....\n",
              "9116    [[-0.057861328125, 0.01318359375, 0.115234375,...\n",
              "9117    [[0.02392578125, -0.046142578125, 0.00390625, ...\n",
              "9118    [[-0.1240234375, 0.2470703125, 0.0218505859375...\n",
              "Name: tokens, Length: 9119, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using CNN"
      ],
      "metadata": {
        "id": "jsjWcgg2tU_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization using ADAM"
      ],
      "metadata": {
        "id": "zJP2QrZZtXn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Initialization**:\n",
        "  *   Initializes two moving average vectors: $m$ (first moment) and $v$ (second moment) to zero\n",
        "  *  Initializes hyperparameters: learning rate $α$, decay rates $β_1, β_2$\n",
        " , and a small constant $\\epsilon$ to prevent division by zero.\n",
        "\n",
        "2. **Gradient Computation**:\n",
        "  * Computes gradients $g_t$ at each time step $t$ using backpropagation.\n",
        "\n",
        "3. **Update Biased Moment Estimates**:\n",
        "  * Updates the biased first moment estimate:\n",
        "  $$\n",
        "  m_t = β_1m_{t-1} + (1- β_1)g_t\n",
        "  $$\n",
        "  * Updates the biased second moment estimate:\n",
        "  $$\n",
        "  v_t = β_2v_{t-1} + (1- β_2)g_t^2\n",
        "  $$\n",
        "4. **Bias Correction**:\n",
        "  * Corrects the bias in the first moment estimate:\n",
        "  $$\n",
        "  \\hat{m}_t = \\frac{m_t}{1 - β_1^t}\n",
        "  $$\n",
        "  * Corrects the bias in the second moment estimate:\n",
        "  $$\n",
        "  \\hat{v}_t = \\frac{v_t}{1 - β_2^t}\n",
        "  $$\n",
        "5. **Update Parameters:**\n",
        "  * Updates the parameters $θ$ using the bias-corrected estimates:\n",
        "  $$\n",
        "  θ_t = θ_{t-1} - α\\frac{\\hat{m_t}}{\\sqrt{\\hat{v_t}} + ϵ}\n",
        "  $$\n",
        "\n"
      ],
      "metadata": {
        "id": "sv2Vpz-WtbQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5dDop58TyDgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Aspect               | Adam                                                                                                    | SGD                                                                                           |\n",
        "|----------------------|---------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|\n",
        "| **Initialization**   | Initializes two moving average vectors \\( m \\) and \\( v \\) to zero.                                      | No moving average initialization.                                                            |\n",
        "| **Gradient Update**  | Updates parameters using biased first and second moment estimates.                                       | Directly uses gradients computed from the current batch of data.                              |\n",
        "| **Learning Rate**    | Adaptive learning rates for each parameter, adjusting individually based on the first and second moments.| Uses a fixed learning rate for all parameters.                                                |\n",
        "| **Gradient Estimation** | Uses moving averages of gradients and squared gradients (first and second moments) for stabilization.   | Does not use moving averages, directly utilizes gradients.                                    |\n",
        "| **Bias Correction**  | Corrects bias introduced by moving averages using bias-corrected estimates.                              | No bias correction applied.                                                                   |\n",
        "| **Hyperparameters**  | Involves multiple hyperparameters: learning rate \\( \\alpha \\), decay rates \\( \\beta_1 \\) and \\( \\beta_2 \\), and a small constant \\( \\epsilon \\). | Mainly involves tuning the learning rate.                                                      |\n",
        "| **Convergence**      | Generally converges faster and is more robust to hyperparameter settings.                                | Can be sensitive to the choice of learning rate and may require careful tuning.                |\n"
      ],
      "metadata": {
        "id": "2HlkpPb-vr9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function(Cross Entropy)"
      ],
      "metadata": {
        "id": "b4wfbou9yEqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-entropy is a widely used loss function in machine learning, particularly for classification tasks. It measures the difference between two probability distributions – the true distribution (actual labels) and the predicted distribution (model's predictions). Cross-entropy quantifies the likelihood of the predicted values under the true distribution and penalizes incorrect predictions more severely than less incorrect ones.\n",
        "\n",
        "\n",
        "\n",
        "*   Binary\n",
        "$$\n",
        "Cross-Entropy Loss = -(ylog(p) + (1 - y)(log(1-p))\n",
        "$$\n",
        "  * $y$: true label\n",
        "  * $p$:  is the predicted probability of the instance being in class 1.\n",
        "*   Multi-Class:\n",
        "$$\n",
        "-\\sum_{i = 1}^{C}y_ilog(p_i)\n",
        "$$\n",
        "  * $C$: number of classes\n",
        "  * $y_i$: is a binary indicator (0 or 1) if class label $i$ is the correct classification for the instance.\n",
        "  * $p_i$: is the predicted probability of the instance being of class $i$\n"
      ],
      "metadata": {
        "id": "3V0OSXw_yH8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Suitability for Classification Tasks**\n",
        "Cross-entropy loss is specifically designed for classification problems. It measures the performance of a classification model whose output is a probability value between 0 and 1. In the context of tweet classification, where the goal is to categorize tweets into different classes (e.g., positive, negative, neutral sentiment), cross-entropy effectively evaluates the difference between the predicted probabilities and the actual class labels.\n",
        "\n",
        "* **Probabilistic Interpretation**\n",
        "Cross-entropy provides a probabilistic interpretation of how well the predicted class probabilities match the actual distribution of classes. This is useful in tweet classification, where the output layer of the CNN often uses a softmax activation function to produce probabilities for each class.\n",
        "\n",
        "* **Penalty for Misclassification**\n",
        "Cross-entropy penalizes incorrect classifications more heavily than less incorrect ones. This means that the model is encouraged to make predictions with higher confidence, leading to better accuracy. In tweet classification, where some tweets might be more ambiguous than others, this characteristic helps the model learn to distinguish between classes more effectively.\n",
        "\n",
        "* **Differentiability**\n",
        "Cross-entropy loss is differentiable, which is essential for gradient-based optimization methods used in training neural networks. It ensures that the gradients are well-defined and the optimization algorithm can update the model parameters to minimize the loss.\n",
        "\n",
        "* **Smooth Convergence**\n",
        "Cross-entropy loss typically leads to smoother and more stable convergence during training. This is important in tweet classification tasks, where the data can be noisy and diverse. A stable loss function helps in achieving better generalization and avoids overfitting."
      ],
      "metadata": {
        "id": "cxftUtew0Lf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel Size"
      ],
      "metadata": {
        "id": "hP_yrfZx2RC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The kernel size in a convolutional layer significantly affects the operation and outcome of the convolution process. It determines the size of the receptive field of the convolutional layer, influencing how much of the input is considered at each step of the convolution. Here's a detailed look at how kernel size affects convolutional layers and their input features:\n",
        "\n",
        "Effect of Kernel Size on Convolutional Layer:\n",
        "\n",
        "1. Receptive Field:\n",
        "\n",
        "  * Larger Kernel Size: A larger kernel (e.g., 5x5 or 7x7) means the convolutional filter can capture more contextual information from a larger area of the input feature map. This can be beneficial for understanding more complex patterns and relationships in the data, but it can also lead to a loss of finer details.\n",
        "  * Smaller Kernel Size: A smaller kernel (e.g., 3x3) focuses on a smaller area, which helps capture fine details and edges. It usually leads to a more detailed and localized understanding of the input features.\n",
        "\n",
        "2. Feature Extraction:\n",
        "\n",
        "  * Larger Kernel Size: With larger kernels, each convolution operation covers more pixels, which can help in extracting more global features. This is useful for understanding broader patterns in the data.\n",
        "  * Smaller Kernel Size: Smaller kernels are effective in capturing local features and details. They are typically used in deeper layers of CNNs, where the combination of multiple small kernels can capture complex patterns.\n",
        "\n",
        "3. Computational Complexity:\n",
        "\n",
        "  * Larger Kernel Size: Increases the number of computations per convolution operation because each filter needs to process more input values. This can lead to higher computational costs and memory usage.\n",
        "  * Smaller Kernel Size: Requires fewer computations per convolution operation, which is generally more efficient and faster, making it preferable for deep networks where many convolutional layers are stacked."
      ],
      "metadata": {
        "id": "0Gdz91Ma2pVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Larger Kernel Size: Captures more context, potentially at the cost of finer details and higher computational expense.\n",
        "- Smaller Kernel Size: Captures fine details, allows for deeper networks, and is computationally efficient."
      ],
      "metadata": {
        "id": "m1WTE0Hp60RQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate and Batch Size"
      ],
      "metadata": {
        "id": "j18owlfVscX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Rate"
      ],
      "metadata": {
        "id": "yUPToGxEsgUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learning rate determines the step size at each iteration while moving toward a minimum of the loss function.\n",
        "\n",
        "Impact on Training:\n",
        "\n",
        "  * **Too High Learning Rate**:\n",
        "\n",
        "    * Pros: Faster convergence initially.\n",
        "    * Cons:\n",
        "      * May overshoot the optimal point.\n",
        "      * Can cause the training process to be unstable, leading to divergence.\n",
        "      * Loss may oscillate or not decrease.\n",
        "  * **Too Low Learning Rate**:\n",
        "\n",
        "    * Pros: More stable and precise convergence.\n",
        "    * Cons:\n",
        "      * Slower convergence.\n",
        "      * May get stuck in local minima or plateaus.\n",
        "      * Requires more training time.\n",
        "\n",
        "**Optimal Learning Rate**: Strikes a balance between convergence speed and stability, allowing the model to learn efficiently without oscillations."
      ],
      "metadata": {
        "id": "HK54CsAayh-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Size"
      ],
      "metadata": {
        "id": "T4ei0o3Qy-Ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size is the number of training examples utilized in one iteration.\n",
        "\n",
        "Impact on Training:\n",
        "\n",
        "* **Small Batch Size**:\n",
        "\n",
        "  * Pros:\n",
        "      * More frequent updates to the model parameters, potentially leading to better generalization.\n",
        "      * Allows for better approximation of the true gradient (stochastic gradient descent).\n",
        "  * Cons:\n",
        "      * More noisy updates can make the training process less stable.\n",
        "      * Can be slower because of less efficient hardware utilization.\n",
        "* **Large Batch Size**:\n",
        "\n",
        "  * Pros:\n",
        "    * More stable and accurate gradient estimates.\n",
        "    * Better utilization of hardware (e.g., GPUs).\n",
        "    * Faster training time per epoch.\n",
        "  * Cons:\n",
        "    * Requires more memory.\n",
        "    * May lead to poorer generalization.\n",
        "    * Less frequent updates might lead to a longer time to reach convergence.\n",
        "\n",
        "**Optimal Batch Size**: Balances the trade-offs between training time, stability, and generalization. It often depends on the specific dataset and the computational resources available."
      ],
      "metadata": {
        "id": "XEN0jlj2y_wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined Effects"
      ],
      "metadata": {
        "id": "a2SglxYQz57k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. High Learning Rate with Large Batch Size:\n",
        "\n",
        "  * Can lead to faster convergence, but the model may not generalize well.\n",
        "  * Risk of missing the optimal point due to large updates.\n",
        "\n",
        "2. Low Learning Rate with Small Batch Size:\n",
        "\n",
        "  * Results in more stable and accurate convergence.\n",
        "  * Training can be very slow and might require many epochs.\n",
        "\n",
        "3. High Learning Rate with Small Batch Size:\n",
        "\n",
        "  * Can cause very noisy updates and instability in training.\n",
        "  * Risk of divergence.\n",
        "\n",
        "4. Low Learning Rate with Large Batch Size:\n",
        "\n",
        "  * Stable training with accurate gradient estimates.\n",
        "  * Slow convergence and potentially higher computational costs per epoch."
      ],
      "metadata": {
        "id": "0PFPrrahz6-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layers with Feed-Forward Layers"
      ],
      "metadata": {
        "id": "wklOuTm14qtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pros of Current Design:**\n",
        "\n",
        "  * **Feature Extraction**: Convolutional layers are excellent at capturing local patterns and hierarchical features. By using multiple convolutional layers with different kernel sizes, the model can learn a variety of features from the input.\n",
        "  * **Flexibility**: Not reducing the output size too much preserves more spatial information, which can be beneficial for complex patterns.\n",
        "  * **Learning Complex Representations**: Fully connected layers after convolutional layers allow the model to learn complex representations by combining features extracted by convolutional layers.\n",
        "\n",
        "**Alternative Design Choices:**\n",
        "  1. **Reducing Output Size with Pooling Layers**:\n",
        "\n",
        "    * Max Pooling: Reduces the spatial dimensions of the input, thus decreasing the number of parameters and computational cost.\n",
        "    * Average Pooling: Similar to max pooling but takes the average of the values instead of the maximum.\n",
        "\n",
        "    Pros:\n",
        "\n",
        "      * Reduces computational cost and memory usage.\n",
        "      * Helps in extracting dominant features and reduces the risk of overfitting.\n",
        "      \n",
        "    Cons:\n",
        "\n",
        "      * Might lose some spatial information that could be crucial for certain tasks.\n",
        "  2. **Global Pooling Layers**:\n",
        "\n",
        "    * Global Max Pooling: Takes the maximum value from each feature map.\n",
        "    * Global Average Pooling: Takes the average value from each feature map.\n",
        "    \n",
        "    Pros:\n",
        "\n",
        "      * Significantly reduces the number of parameters.\n",
        "      * Helps in avoiding overfitting.\n",
        "\n",
        "    Cons:\n",
        "\n",
        "      * Might lose spatial information entirely, which can be a drawback for certain applications.\n",
        "  3. Depthwise Separable Convolutions:\n",
        "\n",
        "    * Depthwise Convolutions: Apply a single convolutional filter per input channel.\n",
        "    * Pointwise Convolutions: Apply a 1x1 convolution to combine the outputs from depthwise convolutions.\n",
        "\n",
        "    Pros:\n",
        "\n",
        "      * Reduces the number of parameters and computational cost significantly while preserving performance.\n",
        "\n",
        "    Cons:\n",
        "\n",
        "      * Might not be as powerful as standard convolutions in capturing complex features."
      ],
      "metadata": {
        "id": "QaobdL-94s2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "dg02yROi6iAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "8K86lADos_85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetSuicidalClfCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TweetSuicidalClfCNN, self).__init__()\n",
        "\n",
        "        self.conv1a = nn.Conv1d(in_channels=300, out_channels=64, kernel_size=3)\n",
        "        self.conv1b = nn.Conv1d(in_channels=300, out_channels=64, kernel_size=5)\n",
        "        self.conv1c = nn.Conv1d(in_channels=300, out_channels=64, kernel_size=7)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.conv2a = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.conv2b = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5)\n",
        "        self.conv2c = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=7)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=3 * 128, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.conv1a(x))\n",
        "        x2 = self.relu(self.conv1b(x))\n",
        "        x3 = self.relu(self.conv1c(x))\n",
        "\n",
        "        x = torch.cat((x1, x2, x3), dim=1)\n",
        "\n",
        "        x1 = self.relu(self.conv2a(x))\n",
        "        x2 = self.relu(self.conv2b(x))\n",
        "        x3 = self.relu(self.conv2c(x))\n",
        "\n",
        "        x = torch.cat((x1, x2, x3), dim=1)\n",
        "\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "dIuRr8Sc6qBZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datset"
      ],
      "metadata": {
        "id": "QmIiVkAOyhrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetSuicidalDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "3VW4MCLFyjGh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "vhBQtTxyzjAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweet_features_vector,\n",
        "                                                    twitter_suicidal_data_cleaned['intention'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "PBsESAhozieZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Steps"
      ],
      "metadata": {
        "id": "CoR69-7MtyTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer_and_loader(epoch, model, train_dataset, test_dataset,\n",
        "                             test_batch_size=32):\n",
        "    min_batch_size = 4\n",
        "    max_batch_size = 16\n",
        "    min_lr = 0.001\n",
        "    max_lr = 0.002\n",
        "\n",
        "    batch_size = randint(min_batch_size, max_batch_size)\n",
        "    learning_rate = min_lr + (max_lr - min_lr) * random()\n",
        "\n",
        "    lr_decay_factor = 0.99\n",
        "    learning_rate *= lr_decay_factor ** epoch\n",
        "\n",
        "    batch_size_increment = 2\n",
        "    if epoch % 10 == 0 and epoch > 0:\n",
        "      batch_size += batch_size_increment\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                             shuffle=True)\n",
        "    return optimizer, train_loader, test_loader"
      ],
      "metadata": {
        "id": "VdjP6WMet0cL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetSuicidalClfCNNTrainer:\n",
        "  def __init__(self, cnn, train_dataset, test_dataset,\n",
        "               criterion=nn.CrossEntropyLoss(), test_batch_size=32):\n",
        "    self._cnn = cnn\n",
        "    self._train_dataset = train_dataset\n",
        "    self._test_dataset = test_dataset\n",
        "    self._criterion = criterion\n",
        "    self._test_batch_size = test_batch_size\n",
        "    self._train_losses = []\n",
        "    self._train_accuracies = []\n",
        "    self._precisions = []\n",
        "    self._recalls = []\n",
        "    self._f1s = []\n",
        "\n",
        "  def __get_optimizer_and_loader(self, epoch):\n",
        "    min_train_batch_size = 4\n",
        "    max_train_batch_size = 16\n",
        "    min_lr = 0.001\n",
        "    max_lr = 0.002\n",
        "\n",
        "    train_batch_size = randint(min_train_batch_size, max_train_batch_size)\n",
        "    learning_rate = min_lr + (max_lr - min_lr) * random()\n",
        "\n",
        "    lr_decay_factor = 0.99\n",
        "    learning_rate *= lr_decay_factor ** epoch\n",
        "\n",
        "    train_batch_size_increment = 2\n",
        "    if epoch % 10 == 0 and epoch > 0:\n",
        "      train_batch_size += train_batch_size_increment\n",
        "\n",
        "    optimizer = optim.Adam(self._cnn.parameters(), lr=learning_rate)\n",
        "    train_loader = DataLoader(self._train_dataset, batch_size=train_batch_size,\n",
        "                              shuffle=True)\n",
        "    test_loader = DataLoader(self._test_dataset, batch_size=self._test_batch_size,\n",
        "                             shuffle=False)\n",
        "    return optimizer, train_loader, test_loader\n",
        "\n",
        "  def __train(self, epoch, optimizer, train_loader):\n",
        "    self._cnn.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      inputs = inputs.permutes(0, 2, 1)\n",
        "      outputs = self._cnn(inputs)\n",
        "      loss = self._criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      _, predited = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predited == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    self._train_losses.append(train_loss)\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    self._train_accuracies.append(train_accuracy)\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "  def __evaluation(self, test_loader):\n",
        "    self._cnn.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.permute(0, 2, 1)\n",
        "            outputs = self._cnn(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, average='binary')\n",
        "    recall = recall_score(all_labels, all_preds, average='binary')\n",
        "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
        "\n",
        "    self._precisions.append(precision)\n",
        "    self._recalls.append(recall)\n",
        "    self._f1s.append(f1)\n",
        "\n",
        "  def __log_epoch(self, epoch, num_epochs, train_loss, train_accuracy):\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "  def __plot_accuracy_and_loss(self, num_epochs):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(num_epochs), self._train_losses, label='Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss per Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(num_epochs), self._train_accuracies, label='Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training Accuracy per Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def __plot_precision_recall_f1(self, num_epochs):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(range(num_epochs), precisions, label='Precision')\n",
        "    plt.plot(range(num_epochs), recalls, label='Recall')\n",
        "    plt.plot(range(num_epochs), f1s, label='F1 Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Precision, Recall, and F1 Score per Epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  def __plot_evaluation_metrics(self, num_epochs):\n",
        "    self.__plot_accuracy_and_loss(num_epochs)\n",
        "    self.__plot_precision_recall_f1(num_epochs)\n",
        "\n",
        "  def execute(self, num_epochs=100):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      optimizer, train_loader, test_loader = self.__get_optimizer_and_loader(epoch)\n",
        "      train_loss, train_accuracy = self.__train(epoch, optimizer, train_loader)\n",
        "      self.__evaluation(test_loader)\n",
        "      self.__log_epoch(epoch, num_epochs, train_loss, train_accuracy)\n",
        "\n",
        "    self.__plot_evaluation_metrics(num_epochs)"
      ],
      "metadata": {
        "id": "TtJc1NsQ8eD1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = TweetSuicidalClfCNN()\n",
        "train_dataset = TweetSuicidalDataset(X_train, y_train)\n",
        "test_dataset = TweetSuicidalDataset(X_test, y_test)\n",
        "\n",
        "clf_cnn_trainer = TweetSuicidalClfCNNTrainer(cnn=cnn,\n",
        "                                             train_dataset=train_dataset,\n",
        "                                             test_dataset=test_dataset)\n",
        "clf_cnn_trainer.execute()"
      ],
      "metadata": {
        "id": "XVxUk1IyBuWy",
        "outputId": "9ba79811-037a-4052-f32a-901266733759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "1429",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1429",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-26da6ba45b6c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                              \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                              test_dataset=test_dataset)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf_cnn_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-f865575b2da2>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_optimizer_and_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-f865575b2da2>\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self, epoch, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-18899b9c634d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1429"
          ]
        }
      ]
    }
  ]
}